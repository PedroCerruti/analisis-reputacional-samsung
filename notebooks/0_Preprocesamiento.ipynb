{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßº Notebook 1: Preprocesamiento de rese√±as\n",
    "\n",
    "En esta notebook se realiza la carga, limpieza y normalizaci√≥n inicial de los datos de rese√±as recolectadas mediante scraping. Se unifican los datasets, se corrigen las fechas, se limpian los textos y se eliminan duplicados o valores nulos antes del an√°lisis exploratorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports y configuraci√≥n general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports y configuraci√≥n general\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import os\n",
    "from dateparser import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuraci√≥n del entorno y rutas\n",
    "\n",
    "Se establecen las configuraciones iniciales del entorno:\n",
    "- Se declaran las rutas a los datos crudos y procesados. Estas rutas permiten guardar versiones intermedias o finales del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de rutas\n",
    "data_raw_dir = '../data/raw'\n",
    "data_processed_dir = '../data/processed'\n",
    "\n",
    "# Crear estructura de outputs\n",
    "output_dirs = [\n",
    "    '../outputs',\n",
    "    '../outputs/visualizations', \n",
    "    '../outputs/analysis_results',\n",
    "    '../outputs/exports',\n",
    "    '../outputs/dashboards'\n",
    "]\n",
    "\n",
    "for dir_path in output_dirs:\n",
    "    os.makedirs(dir_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Funci√≥n de carga y limpieza de rese√±as\n",
    "\n",
    "La funci√≥n `load_and_clean()` permite cargar rese√±as desde un archivo `.json` y aplicar una limpieza b√°sica.  \n",
    "Incluye los siguientes pasos:\n",
    "\n",
    "- **Carga del JSON** y conversi√≥n a DataFrame.\n",
    "- **Normalizaci√≥n del texto** (pasaje a min√∫sculas, remoci√≥n de tildes y puntuaci√≥n).\n",
    "- **Conversi√≥n de fechas** desde formatos ISO o con nombres de meses en espa√±ol, utilizando `dateparser`.\n",
    "- Asignaci√≥n del nombre del producto y retorno del DataFrame limpio.\n",
    "\n",
    "Esta funci√≥n permite reutilizar el mismo proceso para distintos productos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean(filename, product_name):\n",
    "    \"\"\"\n",
    "    Carga y limpia rese√±as desde un archivo JSON.\n",
    "    \n",
    "    Realiza preprocesamiento completo incluyendo limpieza de texto,\n",
    "    normalizaci√≥n de fechas, validaci√≥n de datos y creaci√≥n de \n",
    "    variables auxiliares para an√°lisis posterior.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Nombre del archivo JSON en data/raw\n",
    "        product_name (str): Nombre del producto para identificaci√≥n\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame limpio con las rese√±as procesadas\n",
    "                     Columnas: text, rating, date, useful_votes, producto,\n",
    "                              text_clean, text_length, year_month\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError: Si el archivo JSON no existe\n",
    "        ValueError: Si el JSON tiene estructura incorrecta\n",
    "    \n",
    "    Example:\n",
    "        >>> df = load_and_clean('comentarios_Samsung_A15.json', 'Samsung A15')\n",
    "        >>> print(len(df))  # N√∫mero de rese√±as procesadas\n",
    "    \"\"\"\n",
    "    # Cargar datos desde JSON\n",
    "    file_path = os.path.join(data_raw_dir, filename)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Convertir a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Normalizar texto (min√∫sculas, sin tildes, sin puntuaci√≥n)\n",
    "    def clean_text(text):\n",
    "        if pd.isna(text):\n",
    "            return ''\n",
    "        text = str(text).lower()\n",
    "        text = unidecode(text)  # Remover tildes\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)  # Remover puntuaci√≥n\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()  # Normalizar espacios\n",
    "        return text\n",
    "    \n",
    "    # Aplicar limpieza de texto\n",
    "    df['text_clean'] = df['text'].apply(clean_text)\n",
    "    \n",
    "    # Calcular longitud del texto\n",
    "    df['text_length'] = df['text'].fillna('').str.len()\n",
    "    \n",
    "    # Convertir fechas usando dateparser (maneja formatos en espa√±ol)\n",
    "    df['date'] = df['date'].apply(lambda x: parse(str(x), languages=['es']).strftime('%Y-%m-%d') if parse(str(x), languages=['es']) else None)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Crear columna de a√±o-mes para agrupaciones\n",
    "    df['year_month'] = df['date'].dt.to_period('M')\n",
    "    \n",
    "    # Agregar identificador del producto\n",
    "    df['producto'] = product_name\n",
    "    \n",
    "    print(f\"‚úÖ {product_name}: {len(df)} rese√±as cargadas y procesadas\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Carga de datasets por producto\n",
    "\n",
    "Se cargan las rese√±as de cada producto desde los archivos JSON generados por el scraper.\n",
    "Esto nos permite mantener trazabilidad del origen de cada rese√±a y preparar los datos para su posterior unificaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datasets por producto\n",
    "df_samsung = load_and_clean('comentarios_Samsung_A15.json', 'Samsung A15')\n",
    "df_motorola = load_and_clean('comentarios_Motorola_G32.json', 'Motorola G32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Unificaci√≥n, deduplicaci√≥n y control de nulos\n",
    "\n",
    "Una vez cargadas y limpiadas las rese√±as de cada producto:\n",
    "\n",
    "- Se concatenan en un √∫nico DataFrame (`df_total`).\n",
    "- Se eliminan duplicados basados en el texto de la rese√±a.\n",
    "- Se eliminan filas con valores nulos en campos clave como `text` y `rating`.\n",
    "\n",
    "Se imprime un resumen de los valores nulos y se muestra un preview del DataFrame final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unificar datasets\n",
    "df_total = pd.concat([df_samsung, df_motorola], ignore_index=True)\n",
    "\n",
    "# Eliminar duplicados\n",
    "df_total.drop_duplicates(subset=['text_clean', 'producto'], inplace=True)\n",
    "\n",
    "print(f\"üìä Total de rese√±as despu√©s de deduplicaci√≥n: {len(df_total)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Verificaci√≥n del estado del DataFrame final\n",
    "\n",
    "Se exploran aspectos clave del dataset:\n",
    "\n",
    "- Cantidad de fechas faltantes.\n",
    "- Cantidad total de valores nulos por columna.\n",
    "- Distribuci√≥n de las calificaciones (`rating`), √∫til para entender posibles sesgos.\n",
    "- Estad√≠sticas descriptivas generales (`describe()`), que permiten anticipar outliers o errores de carga.\n",
    "\n",
    "Este chequeo asegura que los datos est√°n listos para pasar al an√°lisis exploratorio (EDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificaci√≥n de calidad de datos\n",
    "print(\"‚Üí Informaci√≥n general del dataset:\")\n",
    "print(df_total.info())\n",
    "\n",
    "print(\"\\n‚Üí Valores nulos por columna:\")\n",
    "print(df_total.isnull().sum())\n",
    "\n",
    "print(\"\\n‚Üí Distribuci√≥n de ratings:\")\n",
    "print(df_total['rating'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\n‚Üí Muestra del dataset final:\")\n",
    "print(df_total.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Guardado del dataset limpio\n",
    "\n",
    "Se exportan las rese√±as unificadas y procesadas a un archivo `.csv` para an√°lisis exploratorio posterior.  \n",
    "Este archivo puede ser utilizado en notebooks siguientes para visualizaciones, NLP u otros an√°lisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear directorio de salida si no existe\n",
    "os.makedirs(data_processed_dir, exist_ok=True)\n",
    "\n",
    "# Guardar en data/processed (datos principales)\n",
    "output_path = os.path.join(data_processed_dir, 'reviews_unificado.csv')\n",
    "df_total.to_csv(output_path, index=False, encoding='utf-8')\n",
    "\n",
    "# Guardar copia en outputs/analysis_results (para f√°cil acceso)\n",
    "output_path_analysis = '../outputs/analysis_results/00_reviews_unificado.csv'\n",
    "df_total.to_csv(output_path_analysis, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"‚úÖ Datos guardados en: {output_path}\")\n",
    "print(f\"‚úÖ Copia guardada en: {output_path_analysis}\")\n",
    "print(f\"üìä Total de rese√±as procesadas: {len(df_total)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
